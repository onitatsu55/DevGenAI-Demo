Amazon SageMaker とは何ですか?,Amazon SageMaker は、完全に管理されたインフラストラクチャ、ツール、ワークフローを使用して、あらゆるユースケース向けにデータを準備し、機械学習 (ML) モデルを構築、トレーニング、デプロイするための完全に管理されたサービスです。
" Amazon SageMaker はどのリージョンで利用できますか?",サポートされている Amazon SageMaker AWS リージョンの一覧については、AWS リージョンサービスのページをご覧ください。また、詳細については、AWS 全般リファレンスガイドの「リージョンエンドポイント」を参照してください。
" Amazon SageMaker のサービス可用性はどのくらいですか?",Amazon SageMaker は高可用性を実現するように設計されています。メンテナンス期間や計画的なダウンタイムはありません。SageMaker API は Amazon の実績のある高可用性データセンターで実行され、各 AWS リージョンの 3 つの施設にサービススタックのレプリケーションが設定されているため、サーバー障害やアベイラビリティーゾーンの停止が発生した場合でもフォールトトレランスが実現します。
Amazon SageMaker はどのようにしてコードを保護しますか?,Amazon SageMaker は、セキュリティグループによって保護され、保存時にオプションで暗号化された ML ストレージボリュームにコードを保存します。
Amazon SageMaker にはどのようなセキュリティ対策がありますか?,Amazon SageMaker は、ML モデル成果物とその他のシステム成果物が転送中および保存時に暗号化されることを保証します。SageMaker API とコンソールへのリクエストは、安全な (SSL) 接続を介して行われます。AWS Identity and Access Management ロールを SageMaker に渡すことで、トレーニングとデプロイのためにユーザーに代わってリソースにアクセスする権限を付与できます。モデル成果物とデータには暗号化された Amazon Simple Storage Service (Amazon S3) バケットを使用し、SageMaker ノートブック、トレーニングジョブ、エンドポイントに AWS Key Management Service (KMS) キーを渡して、接続された ML ストレージボリュームを暗号化できます。Amazon SageMaker は、Amazon Virtual Private Cloud (VPC) と AWS PrivateLink もサポートしています。
Amazon SageMaker はモデル、トレーニングデータ、アルゴリズムを使用または共有しますか?,Amazon SageMaker は、顧客モデル、トレーニングデータ、またはアルゴリズムを使用または共有しません。当社は、お客様がプライバシーとデータセキュリティを非常に重視していることを理解しています。そのため、AWS では、コンテンツの保存場所を決定し、転送中および保存中のコンテンツを保護し、ユーザーによる AWS のサービスとリソースへのアクセスを管理できるシンプルで強力なツールを通じて、コンテンツの所有権と制御権をお客様に提供しています。また、当社は、お客様のコンテンツへの不正アクセスや漏洩を防ぐように設計された、責任ある高度な技術的および物理的な制御も実装しています。お客様は、お客様のコンテンツの所有権を保持し、お客様のコンテンツを処理、保存、およびホストできる AWS のサービスを選択します。当社は、お客様の同意なしに、いかなる目的でもお客様のコンテンツにアクセスしません。
" Amazon SageMaker の料金はどのように請求されますか?",ノートブックのホスティング、モデルのトレーニング、予測の実行、および出力のログ記録に使用する ML コンピューティング、ストレージ、およびデータ処理リソースに対して料金をお支払いいただきます。Amazon SageMaker では、ホストされたノートブック、トレーニング、およびモデルのホスティングに使用するインスタンスの数とタイプを選択できます。使用した分だけ、使用した分だけお支払いいただきます。最低料金や前払いの義務はありません。詳細については、Amazon SageMaker の料金ページと Amazon SageMaker 料金計算ツールをご覧ください。
不要な料金を回避するために、アイドル状態のリソースを検出して停止するなど、Amazon SageMaker のコストを最適化するにはどうすればよいでしょうか?,Amazon SageMaker のリソース使用率を最適化するために採用できるベストプラクティスはいくつかあります。一部のアプローチでは設定の最適化が使用され、その他のアプローチではプログラムによるソリューションが使用されます。この概念に関する完全なガイドは、ビジュアルチュートリアルとコードサンプルを完備しており、このブログ投稿でご覧いただけます。
独自のノートブック、トレーニング、またはホスティング環境がある場合はどうなりますか?,Amazon SageMaker は完全なエンドツーエンドのワークフローを提供しますが、既存のツールを SageMaker で引き続き使用することもできます。ビジネス要件に応じて、各ステージの結果を SageMaker に簡単に転送できます。
Amazon SageMaker では R はサポートされていますか?,"はい、R は Amazon SageMaker でサポートされています。R は、プリインストールされた R カーネルと reticulate ライブラリを含む SageMaker ノートブックインスタンス内で使用できます。Reticulate は、Amazon SageMaker Python SDK 用の R インターフェイスを提供し、ML 実践者が R モデルを構築、トレーニング、調整、およびデプロイできるようにします。"
モデルの不均衡を確認するにはどうすればいいですか?,Amazon SageMaker Clarify は、ML ワークフロー全体にわたって統計的バイアスを検出することで、モデルの透明性を向上させます。SageMaker Clarify は、データの準備中、トレーニング後、および時間の経過に伴って不均衡をチェックし、ML モデルとその予測を説明するのに役立つツールも備えています。結果は、説明可能性レポートを通じて共有できます。
Amazon SageMaker Clarify はどのようなバイアスを検出しますか?,ML モデルのバイアス測定は、バイアスを軽減するための最初のステップです。バイアスは、トレーニング前とトレーニング後、およびデプロイされたモデルの推論で測定できます。バイアスの各尺度は、異なる公平性の概念に対応します。単純な公平性の概念を考慮するだけでも、さまざまなコンテキストに適用できるさまざまな尺度が生まれます。アプリケーションと調査中の状況に有効なバイアスの概念とメトリクスを選択する必要があります。SageMaker は現在、トレーニング データ (SageMaker データ準備の一部として)、トレーニング済みモデル (Amazon SageMaker Experiments の一部として)、およびデプロイされたモデルの推論 (Amazon SageMaker Model Monitor の一部として) のさまざまなバイアス メトリクスの計算をサポートしています。たとえば、トレーニング前には、トレーニング データが代表的であるかどうか (つまり、1 つのグループが過小評価されているかどうか)、およびグループ間でラベル分布に違いがあるかどうかを確認するためのメトリクスを提供します。トレーニング後またはデプロイ中に、メトリクスは、モデルのパフォーマンスがグループ間で異なるかどうか (およびどの程度異なるか) を測定するのに役立ちます。たとえば、エラー率 (モデルの予測が実際のラベルと異なる可能性) を比較することから始めるか、さらに精度 (肯定的な予測が正しい可能性) と再現率 (モデルが肯定的な例を正しくラベル付けする可能性) に細分化します。
Amazon SageMaker Clarify はモデルの説明可能性をどのように向上させますか?,Amazon SageMaker Clarify は Amazon SageMaker Experiments と統合されており、モデルのトレーニング後にモデルの全体的な意思決定プロセスにおける各入力の重要性を詳細に示す機能重要度グラフを提供します。これらの詳細は、特定のモデル入力が全体的なモデルの動作に必要以上の影響を与えているかどうかを判断するのに役立ちます。SageMaker Clarify では、個々の予測の説明も API 経由で利用できます。
Amazon SageMaker Studio とは何ですか?,Amazon SageMaker Studio は、すべての ML 開発ステップを実行できる単一の Web ベースのビジュアルインターフェイスを提供します。SageMaker Studio を使用すると、データの準備、モデルの構築、トレーニング、デプロイに必要な各ステップに完全にアクセス、制御、および可視化できます。データのアップロード、新しいノートブックの作成、モデルのトレーニングと調整、ステップ間の移動による実験の調整、結果の比較、モデルの本番環境へのデプロイをすべて 1 か所で実行できるため、生産性が大幅に向上します。ノートブック、実験管理、自動モデル作成、デバッグとプロファイリング、モデルドリフト検出などのすべての ML 開発アクティビティは、統合された SageMaker Studio ビジュアルインターフェイス内で実行できます。
Amazon SageMaker の RStudio とは何ですか?,Amazon SageMaker の RStudio は、クラウドで初めての完全に管理された RStudio Workbench です。使い慣れた RStudio 統合開発環境 (IDE) をすばやく起動し、作業を中断することなく基盤となるコンピューティング リソースを調整できるため、大規模な R での機械学習 (ML) および分析ソリューションの構築が容易になります。R および Python 開発では、RStudio IDE と Amazon SageMaker Studio ノートブックをシームレスに切り替えることができます。コード、データセット、リポジトリ、その他の成果物を含むすべての作業は、2 つの環境間で自動的に同期されるため、コンテキストの切り替えが減り、生産性が向上します。
" Amazon SageMaker Studio の料金体系はどのようになっていますか?",Amazon SageMaker Studio の使用には追加料金はかかりません。Amazon SageMaker Studio 内で使用するサービスについて、基礎となるコンピューティングとストレージの料金のみをお支払いいただきます。
Amazon SageMaker Studio はどのリージョンでサポートされていますか?,Amazon SageMaker Studio がサポートされているリージョンについては、こちらのドキュメントをご覧ください。
Amazon SageMaker はどのような ML ガバナンスツールを提供していますか?,Amazon SageMaker は、ML ライフサイクル全体にわたって専用の ML ガバナンスツールを提供します。SageMaker Role Manager を使用すると、管理者は数分で最小限の権限を定義できます。SageMaker モデルカードを使用すると、構想から展開まで重要なモデル情報を簡単にキャプチャ、取得、共有できます。また、SageMaker モデルダッシュボードを使用すると、本番環境のモデルの動作に関する情報をすべて 1 か所で入手できます。詳細を表示します。
Amazon SageMaker ロールマネージャーは何をするのですか?,Amazon SageMaker Role Manager を使用すると、最小限のアクセス許可を数分で定義できます。SageMaker Role Manager は、事前構築された IAM ポリシーのカタログを使用して、ML アクティビティとペルソナのベースラインのアクセス許可セットを提供します。ベースラインのアクセス許可をそのまま使用することも、特定のニーズに基づいてさらにカスタマイズすることもできます。いくつかのセルフガイドプロンプトを使用すると、ネットワークアクセス境界や暗号化キーなどの一般的なガバナンス構造をすばやく入力できます。その後、SageMaker Role Manager は IAM ポリシーを自動的に生成します。生成されたロールと関連するポリシーは、AWS IAM コンソールから確認できます。ユースケースに合わせてアクセス許可をさらに調整するには、SageMaker Role Manager で作成した IAM ロールにマネージド IAM ポリシーをアタッチします。また、タグを追加して、ロールを識別し、AWS のサービス全体で整理することもできます。
Amazon SageMaker モデルカードは何をするのですか?,Amazon SageMaker モデルカードは、モデル情報の唯一の信頼できる情報源を作成することで、ML ライフサイクル全体にわたってモデルドキュメントを一元管理および標準化するのに役立ちます。SageMaker モデルカードはトレーニングの詳細を自動的に入力し、ドキュメント作成プロセスを加速します。モデルの目的やパフォーマンス目標などの詳細を追加することもできます。モデル評価結果をモデルカードに添付し、視覚化を提供してモデルのパフォーマンスに関する重要な洞察を得ることができます。SageMaker モデルカードは、PDF 形式でエクスポートすることで、他のユーザーと簡単に共有できます。
Amazon SageMaker モデルダッシュボードは何をするのですか?,Amazon SageMaker モデルダッシュボードでは、デプロイされたモデルとエンドポイントの包括的な概要が提供され、1 つのペインでリソースとモデルの動作違反を追跡できます。Amazon SageMaker モデルモニターおよび Amazon SageMaker Clarify との統合により、データとモデルの品質、バイアスと特徴帰属ドリフトを含む 4 つの側面でモデルの動作を監視できます。SageMaker モデルダッシュボードでは、欠落しているモデル監視ジョブや非アクティブなモデル監視ジョブ、モデル品質、データ品質、バイアスドリフト、特徴帰属ドリフトに関するモデル動作の偏差に関するアラートを設定および受信するための統合エクスペリエンスも提供されます。個々のモデルをさらに検査し、時間の経過とともにモデルのパフォーマンスに影響を与える要因を分析できます。その後、ML 実践者とフォローアップして是正措置を講じることができます。
Amazon SageMaker Autopilot とは何ですか?,Amazon SageMaker Autopilot は、ML モデルを完全に制御し、可視化できる業界初の自動化された機械学習機能です。SageMaker Autopilot は、生データを自動的に検査し、機能プロセッサを適用し、最適なアルゴリズムのセットを選択し、複数のモデルをトレーニングおよび調整し、そのパフォーマンスを追跡し、パフォーマンスに基づいてモデルをランク付けします。これらはすべて、数回クリックするだけで実行できます。その結果、通常モデルのトレーニングに必要な時間のほんの一部でデプロイできる、最高のパフォーマンスを発揮するモデルが完成します。モデルの作成方法と内容を完全に可視化できる SageMaker Autopilot は、Amazon SageMaker Studio と統合されています。SageMaker Studio 内で SageMaker Autopilot によって生成された最大 50 種類のモデルを探索できるため、ユースケースに最適なモデルを簡単に選択できます。SageMaker Autopilot は、ML の経験がない人でも簡単にモデルを作成するために使用できます。また、経験豊富な開発者がベースライン モデルをすばやく開発して、チームがさらに反復処理できるようにするためにも使用できます。
Amazon SageMaker Autopilot ではどのような組み込みアルゴリズムがサポートされていますか?,Amazon SageMaker Autopilot は、XGBoost と Linear Learner という 2 つの組み込みアルゴリズムをサポートしています。
Amazon SageMaker Autopilot ジョブを手動で停止できますか?,はい。ジョブはいつでも停止できます。Amazon SageMaker Autopilot ジョブが停止されると、進行中のすべてのトライアルが停止され、新しいトライアルは開始されません。
Amazon SageMaker をすぐに使い始めるにはどうすればよいですか?,Amazon SageMaker JumpStart を使用すると、ML をすばやく簡単に開始できます。SageMaker JumpStart は、数回クリックするだけですぐにデプロイできる、最も一般的なユースケース向けのソリューションのセットを提供します。ソリューションは完全にカスタマイズ可能で、AWS CloudFormation テンプレートとリファレンスアーキテクチャの使用方法を紹介しているため、ML の導入を加速できます。SageMaker JumpStart は、トランスフォーマー、オブジェクト検出、画像分類モデルなど、150 を超える人気のオープンソースモデルのワンクリックデプロイと微調整もサポートしています。
Amazon SageMaker JumpStart ではどのオープンソースモデルがサポートされていますか?,Amazon SageMaker JumpStart には、PyTorch Hub と TensorFlow Hub の 150 以上の事前トレーニング済みオープンソースモデルが含まれています。画像分類やオブジェクト検出などのビジョンタスクでは、ResNet、MobileNet、Single-Shot Detector (SSD) などのモデルを使用できます。文章分類、テキスト分類、質問回答などのテキストタスクでは、BERT、RoBERTa、DistilBERT などのモデルを使用できます。
" Amazon SageMaker JumpStart にはどのようなソリューションがあらかじめ組み込まれていますか?",SageMaker JumpStart には、ソリューションを本番環境に導入するために必要なすべての AWS サービスが事前設定されたソリューションが含まれています。ソリューションは完全にカスタマイズ可能なので、特定のユースケースやデータセットに合わせて簡単に変更できます。需要予測、不正検出、予測メンテナンスなど 15 を超えるユースケースにソリューションを使用でき、数回クリックするだけで簡単にソリューションをデプロイできます。利用可能なすべてのソリューションの詳細については、SageMaker の開始ページをご覧ください。
組織内の他のユーザーと ML 成果物を共有するにはどうすればよいですか?,Amazon SageMaker JumpStart を使用すると、データ サイエンティストや ML 開発者は、ノートブックやモデルなどの ML アーティファクトを組織内で簡単に共有できます。管理者は、定義された一連のユーザーがアクセスできるリポジトリを設定できます。リポジトリにアクセスする権限を持つすべてのユーザーは、モデルやノートブック、および SageMaker JumpStart 内のパブリック コンテンツを参照、検索、使用できます。ユーザーはアーティファクトを選択して、SageMaker JumpStart でモデルをトレーニングし、エンドポイントをデプロイし、ノートブックを実行できます。
組織内の他のユーザーと ML アーティファクトを共有するために Amazon SageMaker JumpStart を使用する必要があるのはなぜですか?,Amazon SageMaker JumpStart を使用すると、ML アプリケーションを構築する際の市場投入までの時間を短縮できます。組織内の 1 つのチームによって構築されたモデルとノートブックは、数回クリックするだけで組織内の他のチームと簡単に共有できます。社内の知識共有とアセットの再利用により、組織の生産性が大幅に向上します。
"Amazon SageMaker JumpStart の料金体系はどのようになっていますか?",トレーニングジョブやエンドポイントなど、Amazon SageMaker JumpStart から起動された AWS サービスに対しては、SageMaker の料金に基づいて課金されます。SageMaker JumpStart の使用には追加料金はかかりません。
Amazon SageMaker Canvas とは何ですか?,Amazon SageMaker Canvas は、直感的なポイントアンドクリックインターフェイスを備えたコード不要のサービスで、データから高精度の ML ベースの予測を作成できます。SageMaker Canvas を使用すると、ドラッグアンドドロップのユーザーインターフェイスを使用してさまざまなソースのデータにアクセスして組み合わせることができ、データを自動的にクリーニングして準備することで、手動のクリーンアップを最小限に抑えることができます。SageMaker Canvas は、さまざまな最先端の ML アルゴリズムを適用して高精度の予測モデルを見つけ、予測を行うための直感的なインターフェイスを提供します。SageMaker Canvas を使用すると、さまざまなビジネスアプリケーションでより正確な予測を行うことができ、モデル、データ、レポートを共有することで、企業内のデータサイエンティストやアナリストと簡単にコラボレーションできます。SageMaker Canvas の詳細については、SageMaker Canvas の FAQ ページをご覧ください。
" Amazon SageMaker Canvas の料金体系はどのようになっていますか?",Amazon SageMaker Canvas では、使用量に基づいて料金が発生します。SageMaker Canvas を使用すると、複数のソースからデータをインタラクティブに取り込み、調査、準備し、データを使用して高精度の ML モデルをトレーニングし、予測を生成することができます。請求額を決定する要素は 2 つあります。SageMaker Canvas の使用またはログイン時間数に基づくセッション料金と、モデルの構築に使用されたデータセットのサイズに基づくモデルのトレーニング料金です。詳細については、SageMaker Canvas の料金ページをご覧ください。
Amazon SageMaker を使用して継続的インテグレーションおよびデリバリー (CI/CD) パイプラインを構築するにはどうすればよいですか?,Amazon SageMaker Pipelines は、データの準備からモデルのデプロイまで完全に自動化された ML ワークフローの作成を支援し、本番環境で何千もの ML モデルに拡張できるようにします。SageMaker Pipelines には、Amazon SageMaker Studio に接続する Python SDK が付属しており、視覚的なインターフェイスを利用してワークフローの各ステップを構築できます。次に、単一の API を使用して各ステップを接続し、エンドツーエンドのワークフローを作成できます。SageMaker Pipelines は、ステップ間のデータの管理、コードレシピのパッケージ化、実行のオーケストレーションを担当し、数か月かかるコーディングを数時間に短縮します。ワークフローが実行されるたびに、処理されたデータと実行されたアクションの完全な記録が保持されるため、データサイエンティストと ML 開発者は問題をすばやくデバッグできます。
トレーニング済みのすべてのモデルを表示して、本番環境に移行する最適なモデルを選択するにはどうすればよいですか?,Amazon SageMaker Pipelines は、モデルレジストリと呼ばれるトレーニング済みモデルの中央リポジトリを提供します。SageMaker Studio を介して視覚的にモデルを検出し、モデルレジストリにアクセスしたり、Python SDK を介してプログラム的にモデルを検出したりできるため、本番環境にデプロイする目的のモデルを簡単に選択できます。
Amazon SageMaker のどのコンポーネントを Amazon SageMaker Pipelines に追加できますか?,Amazon SageMaker Studio を通じて利用できるコンポーネント (Amazon SageMaker Amazon Clarify、Amazon SageMaker Data Wrangler、Amazon SageMaker Feature Store、Amazon SageMaker Experiments、Amazon SageMaker Debugger、Amazon SageMaker Model Monitor など) を SageMaker Pipelines に追加できます。
ML ワークフロー全体でモデル コンポーネントを追跡するにはどうすればよいですか?,Amazon SageMaker Pipelines は、すべてのモデル構成要素を自動的に追跡し、すべての変更の監査証跡を保持するため、手動での追跡が不要になり、コンプライアンス目標の達成に役立ちます。SageMaker Pipelines を使用すると、データ、コード、トレーニング済みモデルなどを追跡できます。
Amazon SageMaker Pipelines の料金体系はどのようになっていますか?,Amazon SageMaker Pipelines には追加料金はかかりません。基盤となるコンピューティングまたは SageMaker Pipelines 内で使用する個別の AWS サービスに対してのみ料金をお支払いいただきます。
Kubeflow を Amazon SageMaker で使用できますか?,はい。Kubeflow Pipelines 用の Amazon SageMaker コンポーネントはオープンソースのプラグインであり、これを使用すると、Kubeflow Pipelines を使用して ML ワークフローを定義し、データのラベル付け、トレーニング、推論の手順に SageMaker を使用できます。Kubeflow Pipelines は Kubeflow のアドオンであり、ポータブルでスケーラブルなエンドツーエンドの ML パイプラインを構築およびデプロイできます。ただし、Kubeflow Pipelines を使用する場合、ML 運用チームは CPU および GPU インスタンスを使用して Kubernetes クラスターを管理し、その使用率を常に高く保って運用コストを削減する必要があります。データサイエンスチーム全体でクラスターの使用率を最大化することは困難であり、ML 運用チームに追加の運用オーバーヘッドが追加されます。 ML に最適化された Kubernetes クラスターの代替として、SageMaker Components for Kubeflow Pipelines を使用すると、データのラベル付け、フルマネージド型の大規模なハイパーパラメータ調整と分散トレーニングジョブ、ワンクリックの安全でスケーラブルなモデルデプロイメント、Amazon EC2 スポットインスタンスによるコスト効率の高いトレーニングなど、強力な SageMaker 機能を活用できます。ML ジョブを実行するために Kubernetes クラスターを特別に構成および管理する必要はありません。
Kubeflow Pipelines 用の Amazon SageMaker コンポーネントの料金体系はどのようになっていますか?,Kubeflow Pipelines 用の Amazon SageMaker コンポーネントの使用には追加料金はかかりません。
Amazon SageMaker はどのようにして ML 用のデータを準備するのでしょうか?,Amazon SageMaker Data Wrangler は、ML 用のデータの集約と準備にかかる時間を短縮します。Amazon SageMaker Studio の単一のインターフェイスから、Amazon S3、Amazon Athena、Amazon Redshift、AWS Lake Formation、Amazon SageMaker Feature Store、Snowflake から数回クリックするだけでデータを参照およびインポートできます。また、40 を超えるデータソースから転送され、Amazon AppFlow によって AWS Glue Data Catalog に登録されたデータをクエリしてインポートすることもできます。SageMaker Data Wrangler は、生データを自動的に読み込み、集約して表示します。データを SageMaker Data Wrangler にインポートすると、自動的に生成された列の概要とヒストグラムが表示されます。その後、SageMaker Data Wrangler のデータ品質とインサイト レポートを使用して、データをさらに深く理解し、潜在的なエラーを特定できます。このレポートには、概要統計とデータ品質の警告が表示されます。Amazon SageMaker Clarify でサポートされているバイアス分析を SageMaker Data Wrangler から直接実行して、データ準備中に潜在的なバイアスを検出することもできます。そこから、SageMaker Data Wrangler の事前構築された変換を使用してデータを準備できます。データが準備されると、Amazon SageMaker Pipelines を使用して完全に自動化された ML ワークフローを構築したり、そのデータを Amazon SageMaker Feature Store にインポートしたりできます。
Amazon SageMaker Data Wrangler を使用してモデル機能を作成するにはどうすればよいですか?,Amazon SageMaker Data Wrangler は、コードを 1 行も書かずに、データを自動的に新しい機能に変換できます。SageMaker Data Wrangler は、事前設定されたデータ変換、欠損データの補完、ワンホットエンコーディング、主成分分析 (PCA) を使用した次元削減、および時系列固有のトランスフォーマーの選択肢を提供します。たとえば、テキストフィールド列を 1 回のクリックで数値列に変換できます。SageMaker Data Wrangler のスニペットライブラリからコードスニペットを作成することもできます。
Amazon SageMaker Data Wrangler でデータを視覚化するにはどうすればよいですか?,Amazon SageMaker Data Wrangler は、堅牢な事前設定された視覚化テンプレートのセットを使用して、データを理解し、潜在的なエラーや極端な値を特定するのに役立ちます。ヒストグラム、散布図、ターゲット漏洩検出などの ML 固有の視覚化はすべて、コードを 1 行も記述せずに利用できます。独自の視覚化を作成および編集することもできます。
Amazon SageMaker Data Wrangler の料金体系はどのようになっていますか?,Amazon SageMaker Data Wrangler で使用するすべての ML コンピューティング、ストレージ、およびデータ処理リソースに対して料金が発生します。SageMaker Data Wrangler の料金の詳細は、こちらで確認できます。AWS 無料利用枠の一部として、SageMaker Data Wrangler を無料で使い始めることもできます。
Amazon SageMaker Data Wrangler で準備されたデータを使用して機械学習モデルをトレーニングするにはどうすればよいですか?,Amazon SageMaker Data Wrangler は、Amazon SageMaker Autopilot でデータを準備し、機械学習モデルをシームレスにトレーニングできる統合エクスペリエンスを提供します。SageMaker Autopilot は、データに基づいて最適な ML モデルを自動的に構築、トレーニング、調整します。SageMaker Autopilot を使用すると、データとモデルの完全な制御と可視性を維持できます。また、SageMaker Data Wrangler で準備された機能を既存のモデルで使用することもできます。ユーザーインターフェイス (UI) でジョブを設定するか、オーケストレーションコードを含むノートブックをエクスポートすることにより、Amazon SageMaker Data Wrangler 処理ジョブを SageMaker トレーニングパイプラインの一部として実行するように設定できます。
履歴データに基づいて機能を準備した場合、Amazon SageMaker Data Wrangler は新しいデータをどのように処理しますか?,SageMaker Data Wrangler UI から直接 Amazon SageMaker 処理ジョブを設定および起動できます。これには、データ処理ジョブのスケジュール設定や、データソースのパラメータ化などがあり、大規模な新しいデータバッチを簡単に変換できます。
Amazon SageMaker Data Wrangler は CI/CD プロセスとどのように連携しますか?,データの準備ができたら、Amazon SageMaker Data Wrangler は SageMaker Data Wrangler フローを本番環境にプロモートするためのさまざまなオプションを提供し、MLOps および CI/CD 機能とシームレスに統合します。SageMaker Data Wrangler UI から直接 SageMaker 処理ジョブを設定して起動できます。これには、データ処理ジョブのスケジュール設定や、データソースのパラメータ化などがあり、大規模な新しいデータバッチを簡単に変換できます。また、SageMaker Data Wrangler は SageMaker 処理および SageMaker Spark コンテナとシームレスに統合されるため、SageMaker SDK を使用して SageMaker Data Wrangler を本番ワークフローに簡単に統合できます。
"Amazon SageMaker Data Wrangler Quick Model はどのモデルを使用しますか?",Amazon SageMaker Data Wrangler は、ボタンを数回クリックするだけで、デフォルトのハイパーパラメータを使用して XGBoost モデルを分割してトレーニングします。問題の種類に基づいて、SageMaker Data Wrangler はモデルの概要、機能の概要、混同行列を提供し、データ準備フローを反復できるように迅速に洞察を提供します。
" Amazon SageMaker Data Wrangler はどのくらいのサイズのデータをサポートしますか?",Amazon SageMaker Data Wrangler は、データのインポートにトップ K、ランダム、層別サンプリングなどのさまざまなサンプリング手法をサポートしているため、SageMaker Data Wrangler の UI を使用してデータをすばやく変換できます。大規模または幅広いデータセットを使用している場合は、SageMaker Data Wrangler インスタンスのサイズを増やしてパフォーマンスを向上させることができます。フローを作成したら、SageMaker Data Wrangler 処理ジョブを使用してデータセット全体を処理できます。
Amazon SageMaker Data Wrangler は Amazon SageMaker Feature Store と連携しますか?,Amazon SageMaker Data Wrangler で準備された機能の保存先として、Amazon SageMaker Feature Store を設定できます。これは UI で直接行うことも、SageMaker Feature Store を保存先としてデータ処理用に特別に生成されたノートブックをエクスポートすることもできます。
ML モデルの特徴をどのように保存しますか?,Amazon SageMaker Feature Store は、低レイテンシー (ミリ秒単位) の読み取りと書き込みを備えたデータ機能の中央リポジトリを提供します。SageMaker Feature Store を通じて機能を保存、取得、検出、共有できるため、安全なアクセスと制御により、モデルやチーム間で簡単に再利用できます。SageMaker Feature Store は、バッチまたはストリーミング パイプラインを介して生成されたオンライン機能とオフライン機能の両方をサポートしています。機能のバックフィルをサポートし、オンライン ストアとオフライン ストアの両方を提供して、モデルのトレーニングと推論で使用される機能間の整合性を維持します。
オンライン機能とオフライン機能の一貫性を維持するにはどうすればよいですか?,Amazon SageMaker Feature Store は、追加の管理やコードなしで、オンライン機能とオフライン機能間の一貫性を自動的に維持します。SageMaker Feature Store は完全に管理されており、トレーニング環境と推論環境全体で一貫性を維持します。
特定の瞬間の特徴を再現するにはどうすればよいでしょうか?,Amazon SageMaker Feature Store は、すべての特徴のタイムスタンプをあらゆる時点で保持します。これにより、ビジネス要件やコンプライアンス要件に応じて、任意の期間に特徴を取得できます。特定の時点からモデルを再現することで、モデルの特徴とその値が最初に作成されたときから現在まで簡単に説明できます。
オフライン機能とは何ですか?,オフライン機能は、長期間にわたって非常に大きなボリュームにアクセスする必要があるため、トレーニングに使用されます。これらの機能は、高スループット、高帯域幅のリポジトリから提供されます。
オンライン機能とは何ですか?,オンライン機能は、リアルタイム予測が必要なアプリケーションで使用されます。オンライン機能は、高速予測のために 1 桁ミリ秒のレイテンシで高スループット リポジトリから提供されます。
Amazon SageMaker Feature Store の料金体系はどのようになっていますか?,Amazon SageMaker Feature Store は、AWS 無料利用枠の一部として無料で開始できます。SageMaker Feature Store では、機能ストアへの書き込み、およびオンライン機能ストアからの読み取りと保存に対して料金が発生します。料金の詳細については、SageMaker の料金ページをご覧ください。
Amazon SageMaker はデータのラベル付けに何を提供しますか?,Amazon SageMaker は、Amazon SageMaker Ground Truth Plus と Amazon SageMaker Ground Truth という 2 つのデータラベリングサービスを提供しています。どちらのオプションでも、画像、テキストファイル、動画などの生データを識別し、有益なラベルを追加して、ML モデル用の高品質なトレーニングデータセットを作成できます。詳細については、SageMaker データラベリングの Web ページをご覧ください。
地理空間データとは何ですか?,地理空間データは、地球の表面上の特徴やオブジェクトを表します。地理空間データの 1 つ目のタイプはベクター データで、ポイント、ライン、ポリゴンなどの 2 次元ジオメトリを使用して、道路や土地の境界などのオブジェクトを表します。地理空間データの 2 つ目のタイプはラスター データで、衛星、航空プラットフォーム、リモート センシング データによってキャプチャされた画像などです。このデータ タイプは、ピクセルのマトリックスを使用して、特徴の位置を定義します。さまざまなデータを保存するためにラスター形式を使用できます。地理空間データの 3 つ目のタイプは、ジオタグ付き位置データです。これには、エッフェル塔などの興味のあるポイント、位置がタグ付けされたソーシャル メディアの投稿、緯度と経度の座標、またはさまざまなスタイルや形式の住所が含まれます。
Amazon SageMaker の地理空間機能とは何ですか?,Amazon SageMaker の地理空間機能により、データサイエンティストや機械学習 (ML) エンジニアは、地理空間データを使用して予測を行うための ML モデルの構築、トレーニング、デプロイが容易になります。Amazon S3 から Planet Labs の衛星データなどの独自のデータを持ち込んだり、AWS のオープンデータ、Amazon Location Service、その他の Amazon SageMaker 地理空間データソースからデータを取得したりできます。
Amazon SageMaker で地理空間 ML を使用する必要があるのはなぜですか?,Amazon SageMaker の地理空間機能を使用すると、DIY ソリューションよりも速く地理空間データの予測を行うことができます。Amazon SageMaker の地理空間機能により、既存の顧客データレイク、オープンソースデータセット、その他の Amazon SageMaker 地理空間データソースから地理空間データに簡単にアクセスできます。Amazon SageMaker の地理空間機能は、効率的なデータ準備、モデルトレーニング、推論のための専用アルゴリズムを提供することで、カスタムインフラストラクチャとデータ前処理機能を構築する必要性を最小限に抑えます。また、Amazon SageMaker Studio からカスタム視覚化とデータを作成し、組織と共有することもできます。Amazon SageMaker の地理空間機能には、農業、不動産、保険、金融サービスで一般的に使用される事前トレーニング済みモデルが含まれています。
Amazon SageMaker Studio ノートブックとは何ですか?,Amazon SageMaker Studio ノートブックは、すぐに始められる、共同作業可能な、管理された Jupyter ノートブックです。Amazon SageMaker Studio ノートブックは、SageMaker の専用 ML ツールやその他の AWS サービスと統合され、ML 用の完全に統合された開発環境 (IDE) である Amazon SageMaker Studio でのエンドツーエンドの ML 開発を実現します。
Amazon SageMaker Studio ノートブックは、インスタンスベースのノートブックとどう違うのでしょうか?,SageMaker Studio ノートブックには、インスタンスベースのノートブックとは異なる重要な機能がいくつかあります。Studio ノートブックを使用すると、手動でインスタンスをプロビジョニングして操作可能になるまで待つことなく、ノートブックをすばやく起動できます。ノートブックを読み込んで実行するための UI を起動する起動時間は、インスタンスベースのノートブックよりも高速です。また、UI 内からいつでも多数のインスタンスタイプから選択できる柔軟性もあります。新しいインスタンスを開始してノートブックを移植するために、AWS マネジメントコンソールに移動する必要はありません。各ユーザーには、特定のインスタンスから独立した独立したホームディレクトリがあります。このディレクトリは、すべてのノートブックサーバーとカーネルが起動すると自動的にマウントされるため、インスタンスを切り替えてノートブックを表示および実行する場合でも、ノートブックやその他のファイルにアクセスできます。SageMaker Studio ノートブックは AWS IAM Identity Center (AWS SSO の後継) と統合されているため、組織の認証情報を使用してノートブックに簡単にアクセスできます。ノートブックの共有は、SageMaker Studio ノートブックに統合された機能です。 1 回のクリックでノートブックを同僚と共有したり、1 つのノートブックを同時に共同編集したりすることもできます。
Amazon SageMaker Studio ノートブックはどのように機能しますか?,Amazon SageMaker Studio ノートブックは、ワンクリックですばやくスピンできる Jupyter ノートブックです。基盤となるコンピューティング リソースは完全に伸縮自在であるため、利用可能なリソースを簡単に増減でき、変更は作業を中断することなくバックグラウンドで自動的に行われます。SageMaker では、ノートブックをワンクリックで共有することもできます。ノートブックを他のユーザーと簡単に共有でき、同じ場所に保存されたまったく同じノートブックを入手できます。SageMaker Studio ノートブックでは、AWS IAM Identity Center (AWS SSO の後継) を使用して、会社の認証情報でサインインできます。ノートブックの実行に必要な依存関係は、共有時にノートブックにカプセル化された作業イメージで自動的に追跡されるため、チーム内およびチーム間でノートブックを共有するのは簡単です。
Amazon SageMaker の共有スペースとは何ですか?,機械学習の専門家は、チームメイトが Amazon SageMaker Studio ノートブックを一緒に読み、編集できる共有ワークスペースを作成できます。共有スペースを使用すると、チームメイトは同じノートブックファイルを共同編集し、ノートブックコードを同時に実行し、結果を一緒に確認して、やり取りをなくし、コラボレーションを効率化できます。共有スペースでは、ML チームは BitBucket や AWS CodeCommit などのサービスのサポートを組み込むことができるため、ノートブックのさまざまなバージョンを簡単に管理し、時間の経過とともに変更を比較できます。実験や ML モデルなど、ノートブック内から作成されたリソースはすべて自動的に保存され、作成された特定のワークスペースに関連付けられるため、チームはより簡単に整理された状態を維持し、ML モデル開発を加速できます。
Amazon SageMaker Studio ノートブックは他の AWS サービスとどのように連携しますか?,Amazon SageMaker Studio ノートブックを使用すると、分散トレーニング、バッチ変換、ホスティング、実験管理など、すべての SageMaker 機能にアクセスできます。SageMaker ノートブックからは、Amazon S3、Amazon Redshift、AWS Glue、Amazon EMR、AWS Lake Formation のデータセットなどの他のサービスにアクセスできます。
Amazon SageMaker Studio ノートブックの料金体系はどのようになっていますか?,SageMaker Studio ノートブックを使用する場合は、コンピューティングとストレージの両方に対して料金が発生します。コンピューティングインスタンスタイプ別の料金については、Amazon SageMaker の料金表をご覧ください。ノートブックと、データファイルやスクリプトなどの関連アーティファクトは、Amazon EFS に保存されます。ストレージ料金については、Amazon EFS の料金表をご覧ください。AWS 無料利用枠の一部として、Amazon SageMaker Studio ノートブックを無料で使い始めることができます。
SageMaker Studio で作成および実行されるノートブックごとに個別に料金が発生しますか?,いいえ。同じコンピューティングインスタンスで複数のノートブックを作成して実行できます。個々のアイテムではなく、使用したコンピューティングに対してのみ料金が発生します。詳細については、メータリングガイドをご覧ください。ノートブックに加えて、SageMaker Studio でターミナルとインタラクティブシェルを起動して実行することもできます。これらはすべて同じコンピューティングインスタンスで実行されます。各アプリケーションは、コンテナまたはイメージ内で実行されます。SageMaker Studio には、データサイエンスと ML 用に構築され、事前構成された組み込みイメージがいくつか用意されています。SageMaker Studio 開発者環境の詳細については、SageMaker Studio ノートブックの使用ガイドをご覧ください。
ノートブックで使用されるリソースを監視およびシャットダウンするにはどうすればよいですか?,SageMaker Studio ビジュアルインターフェイスと AWS マネジメントコンソールの両方を使用して、SageMaker Studio ノートブックで使用されるリソースを監視およびシャットダウンできます。詳細については、ドキュメントを参照してください。
SageMaker Studio ノートブックを実行しています。ブラウザを閉じたり、ノートブックのタブを閉じたり、ブラウザを開いたままにしたりしても料金は発生しますか?,はい、コンピューティングに対しては引き続き課金されます。これは、AWS マネジメントコンソールで Amazon EC2 インスタンスを起動し、ブラウザを閉じるのと似ています。Amazon EC2 インスタンスは引き続き実行されており、インスタンスを明示的にシャットダウンしない限り、引き続き課金されます。
Amazon SageMaker Studio ドメインの作成と設定には料金がかかりますか?,いいえ、ユーザープロファイルの追加、更新、削除など、Amazon SageMaker Studio ドメインの作成や設定に対して料金は発生しません。
Amazon SageMaker Studio ノートブックまたはその他の Amazon SageMaker サービスの明細料金を確認するにはどうすればよいですか?,管理者は、AWS 請求コンソールで、SageMaker Studio を含む Amazon SageMaker の明細料金リストを表示できます。SageMaker の AWS マネジメントコンソールで、上部のメニューの [サービス] を選択し、検索ボックスに「請求」と入力してドロップダウンから [請求] を選択し、左側のパネルで [請求書] を選択します。[詳細] セクションで、SageMaker をクリックしてリージョンのリストを展開し、明細料金にドリルダウンできます。
Amazon SageMaker Studio Lab とは何ですか?,Amazon SageMaker Studio Lab は、コンピューティング、ストレージ (最大 15 GB)、セキュリティをすべて無料で提供する無料の ML 開発環境であり、誰でも ML を学習して実験できます。開始するために必要なのは有効なメール ID だけです。インフラストラクチャを構成したり、ID とアクセスを管理したり、AWS アカウントにサインアップしたりする必要はありません。SageMaker Studio Lab は、GitHub 統合を通じてモデル構築を加速し、最も人気のある ML ツール、フレームワーク、ライブラリが事前設定されているため、すぐに開始できます。SageMaker Studio Lab は作業を自動的に保存するため、セッション間で再起動する必要はありません。ノートパソコンを閉じて後で戻ってくるだけです。
Amazon SageMaker Studio Lab を使用する必要があるのはなぜですか?,Amazon SageMaker Studio Lab は、ML クラスや実験にセットアップが不要な無料のノートブック開発環境を必要とする学生、研究者、データ サイエンティスト向けです。SageMaker Studio Lab は、本番環境は必要ないが、SageMaker 機能のサブセットを使用して ML スキルを向上させたいユーザーに最適です。SageMaker セッションは自動的に保存されるため、ユーザーは各ユーザー セッションで中断したところから再開できます。
Amazon SageMaker Studio Lab は他の AWS サービスとどのように連携しますか?,Amazon SageMaker Studio Lab は AWS 上に構築されたサービスで、Amazon S3 や Amazon EC2 など、Amazon SageMaker Studio と同じコアサービスの多くを使用します。他のサービスとは異なり、お客様は AWS アカウントを必要としません。代わりに、メールアドレスを使用して Amazon SageMaker Studio Lab 固有のアカウントを作成します。これにより、ユーザーは ML ノートブックを実行するための限定環境 (15 GB のストレージ、12 時間のセッション) にアクセスできるようになります。
Amazon SageMaker Canvas とは何ですか?,Amazon SageMaker Canvas は、ビジネスアナリストがコードを記述したり ML の専門知識を必要とせずに ML モデルを構築し、正確な予測を生成できる視覚的なドラッグアンドドロップサービスです。SageMaker Canvas を使用すると、さまざまなソースからのデータに簡単にアクセスして組み合わせたり、データを自動的にクリーンアップしてさまざまなデータ調整を適用したり、ワンクリックで正確な予測を生成する ML モデルを構築したりできます。また、結果を簡単に公開したり、モデルを説明および解釈したり、組織内の他のユーザーとモデルを共有してレビューしたりすることもできます。
" Amazon SageMaker Canvas はどのようなデータソースをサポートしていますか?",Amazon SageMaker Canvas を使用すると、Amazon S3 や Amazon Redshift など、アカウントがアクセスできる AWS データソースをシームレスに検出できます。SageMaker Canvas のビジュアル ドラッグ アンド ドロップ インターフェイスを使用して、データを参照およびインポートできます。さらに、ローカル ディスクからファイルをドラッグ アンド ドロップしたり、事前に構築されたコネクタを使用して Snowflake などのサードパーティ ソースからデータをインポートしたりすることもできます。
Amazon SageMaker Canvas で正確な予測を生成する ML モデルを構築するにはどうすればよいですか?,ソースを接続し、データセットを選択し、データを準備したら、予測するターゲット列を選択してモデル作成ジョブを開始できます。Amazon SageMaker Canvas は、問題の種類を自動的に識別し、新しい関連機能を生成し、線形回帰、ロジスティック回帰、ディープラーニング、時系列予測、勾配ブースティングなどの ML 技術を使用して包括的な予測モデルセットをテストし、データセットに基づいて正確な予測を行うモデルを構築します。
" Amazon SageMaker Canvas でモデルを構築するにはどのくらいの時間がかかりますか? モデル作成中の進行状況を監視するにはどうすればよいですか?",モデルの構築にかかる時間は、データセットのサイズによって異なります。データセットが小さい場合は 30 分未満で完了しますが、データセットが大きい場合は数時間かかることがあります。モデル作成ジョブが進行するにつれて、Amazon SageMaker Canvas は、ジョブの完了率やジョブ完了までの残り時間など、詳細なビジュアル更新を提供します。
Amazon SageMaker Experiments とは何ですか?,Amazon SageMaker Experiments は、ML モデルの反復を整理して追跡するのに役立ちます。SageMaker Experiments は、入力パラメータ、設定、結果を自動的にキャプチャし、「実験」として保存することで、反復の管理に役立ちます。Amazon SageMaker Studio のビジュアル インターフェイス内で作業して、アクティブな実験を参照したり、特性別に以前の実験を検索したり、以前の実験とその結果を確認したり、実験結果を視覚的に比較したりできます。
Amazon SageMaker デバッガーとは何ですか?,Amazon SageMaker Debugger は、トレーニング中に混同行列や学習勾配などのリアルタイムのメトリクスを自動的にキャプチャし、モデルの精度向上に役立ちます。SageMaker Debugger のメトリクスは、Amazon SageMaker Studio で視覚化して簡単に理解できます。SageMaker Debugger は、一般的なトレーニングの問題が検出されたときに警告や修復アドバイスを生成することもできます。また、SageMaker Debugger は、CPU、GPU、ネットワーク、メモリなどのシステムリソースをリアルタイムで自動的に監視およびプロファイルし、これらのリソースの再割り当てに関する推奨事項を提供します。これにより、トレーニング中にリソースを効率的に使用でき、コストとリソースを削減できます。
Amazon SageMaker は分散トレーニングをサポートしていますか?,はい。Amazon SageMaker は、これらの分散戦略を手動で構築して最適化するのにかかる時間のほんの一部で、ディープラーニングモデルと大規模なトレーニングセットを AWS GPU インスタンス全体に自動的に分散できます。SageMaker が適用する 2 つの分散トレーニング手法は、データ並列処理とモデル並列処理です。データ並列処理は、複数の GPU インスタンスにデータを均等に分割して各インスタンスを同時にトレーニングできるようにすることで、トレーニング速度を向上させるために適用されます。モデル並列処理は、単一の GPU に保存するには大きすぎるモデルで役立ち、複数の GPU に分散する前にモデルを小さな部分に分割する必要があります。PyTorch および TensorFlow トレーニングスクリプトに数行のコードを追加するだけで、SageMaker はデータ並列処理またはモデル並列処理を自動的に適用し、モデルをより迅速に開発およびデプロイできます。SageMaker は、グラフ分割アルゴリズムを使用して各 GPU の計算のバランスを取りながら GPU インスタンス間の通信を最小限に抑えることで、モデルを分割するための最適なアプローチを決定します。 SageMaker は、AWS のコンピューティングとネットワークを最大限に活用するアルゴリズムを通じて分散トレーニングジョブを最適化し、ほぼ線形のスケーリング効率を実現します。これにより、手動のオープンソース実装よりも速くトレーニングを完了できます。
Amazon SageMaker トレーニングコンパイラとは何ですか?,Amazon SageMaker Training Compiler は、グラフレベルとカーネルレベルの最適化により、GPU をより効率的に使用して DL モデルのトレーニングを最大 50% 高速化するディープラーニング (DL) コンパイラです。SageMaker Training Compiler は SageMaker の TensorFlow および PyTorch のバージョンと統合されているため、最小限のコード変更でこれらの一般的なフレームワークのトレーニングを高速化できます。
Amazon SageMaker トレーニングコンパイラはどのように機能しますか?,Amazon SageMaker Training Compiler は、DL モデルを高水準言語表現からハードウェアに最適化された命令に変換することで、ネイティブフレームワークを使用したジョブよりも高速にトレーニングし、トレーニングジョブを高速化します。具体的には、SageMaker Training Compiler は、グラフレベルの最適化 (演算子の融合、メモリ計画、代数の簡素化)、データフローレベルの最適化 (レイアウト変換、共通部分式の除去)、バックエンドの最適化 (メモリレイテンシーの隠蔽、ループ指向の最適化) を使用して、ハードウェアリソースをより効率的に使用し、結果としてトレーニングを高速化する、最適化されたモデルトレーニングジョブを生成します。
Amazon SageMaker トレーニングコンパイラーを使用するにはどうすればよいですか?,Amazon SageMaker トレーニングコンパイラは、SageMaker Python SDK と SageMaker Hugging Face ディープラーニングコンテナに組み込まれています。ワークフローを変更しなくても、高速化のメリットを享受できます。Amazon SageMaker ノートブックインスタンス、Amazon SageMaker Studio、AWS SDK for Python (Boto3)、AWS コマンドラインインターフェイスなど、SageMaker インターフェイスのいずれかを使用して、これまでと同じ方法でトレーニングジョブを実行できます。フレームワークエスティメーターオブジェクトを作成するときに、TrainingCompilerConfig クラスをパラメータとして追加することで、SageMaker トレーニングコンパイラを有効にすることができます。実際には、これは単一の GPU インスタンスの既存のトレーニングジョブスクリプトに数行のコードを追加することを意味します。最新の詳細なドキュメント、サンプルノートブック、および例は、ドキュメントで入手できます。
Amazon SageMaker トレーニングコンパイラの料金はいくらですか?,トレーニング コンパイラは SageMaker トレーニング機能であり、SageMaker のお客様だけに追加料金なしで提供されます。トレーニング コンパイラを使用すると、トレーニング時間が短縮されるため、お客様は実際にコストを削減できます。
マネージドスポットトレーニングとは何ですか?,Amazon SageMaker を使用したマネージドスポットトレーニングでは、Amazon EC2 スポットインスタンスを使用して ML モデルをトレーニングしながら、モデルのトレーニングコストを最大 90% 削減できます。
マネージドスポットトレーニングを使用するにはどうすればよいですか?,トレーニング ジョブを送信するときにマネージド スポット トレーニング オプションを有効にし、スポット容量を待機する時間も指定します。Amazon SageMaker は Amazon EC2 スポット インスタンスを使用してジョブを実行し、スポット容量を管理します。トレーニング ジョブの実行中と容量を待機中の両方のステータスを完全に把握できます。
マネージドスポットトレーニングはいつ使用すればよいですか?,マネージド スポット トレーニングは、トレーニング実行に柔軟性があり、トレーニング ジョブのコストを最小限に抑えたい場合に最適です。マネージド スポット トレーニングを使用すると、ML モデルのトレーニング コストを最大 90% 削減できます。
マネージドスポットトレーニングはどのように機能しますか?,マネージドスポットトレーニングでは、トレーニングに Amazon EC2 スポットインスタンスを使用します。これらのインスタンスは、AWS が容量を必要とするときにプリエンプトできます。その結果、マネージドスポットトレーニングジョブは、容量が利用可能になったときに少しずつ実行できます。中断が発生した場合、トレーニングジョブを最初からやり直す必要はありません。Amazon SageMaker は最新のモデルチェックポイントを使用してトレーニングジョブを再開できるためです。SageMaker に組み込まれたフレームワークとコンピュータービジョンアルゴリズムにより、定期的なチェックポイントが有効になり、カスタムモデルでチェックポイントを有効にできます。
マネージド スポット トレーニングでは定期的にチェックポイントを設定する必要がありますか?,長時間実行されるトレーニングジョブの一般的なベストプラクティスとして、定期的なチェックポイントをお勧めします。これにより、容量がプリエンプトされた場合にマネージドスポットトレーニングジョブが再開されるのを防ぎます。チェックポイントを有効にすると、Amazon SageMaker は最後のチェックポイントからマネージドスポットトレーニングジョブを再開します。
マネージド スポット トレーニング ジョブによるコスト削減はどのように計算しますか?,マネージドスポットトレーニングジョブが完了すると、AWS マネジメントコンソールで節約額を確認できるほか、トレーニングジョブの実行期間と請求期間の差の割合としてコスト節約額を計算することもできます。マネージドスポットトレーニングジョブが何度中断されても、データがダウンロードされた期間に対して 1 回のみ課金されます。
マネージド スポット トレーニングで使用できるインスタンスはどれですか?,"マネージドスポットトレーニングは、Amazon SageMaker でサポートされているすべてのインスタンスで使用できます。"
マネージドスポットトレーニングではどの AWS リージョンがサポートされていますか?,"マネージドスポットトレーニングは、Amazon SageMaker が現在利用可能なすべての AWS リージョンでサポートされています。"
トレーニングに使用できるデータセットのサイズに制限はありますか?," Amazon SageMaker でモデルのトレーニングに使用できるデータセットのサイズには、固定の制限はありません。"
Amazon SageMaker はモデルを生成するためにどのようなアルゴリズムを使用しますか?,Amazon SageMaker には、線形回帰、ロジスティック回帰、k-means クラスタリング、主成分分析、因数分解マシン、ニューラルトピックモデリング、潜在ディリクレ配分法、勾配ブースティングツリー、sequence2sequence、時系列予測、word2vec、画像分類などの組み込みアルゴリズムが含まれています。SageMaker は、最適化された Apache MXNet、Tensorflow、Chainer、PyTorch、Gluon、Keras、Horovod、Scikit-learn、Deep Graph Library コンテナも提供します。さらに、Amazon SageMaker は、文書化された仕様に準拠した Docker イメージを通じて提供されるカスタムトレーニングアルゴリズムをサポートします。
"自動モデルチューニングとは何ですか?",ほとんどの ML アルゴリズムは、基礎となるアルゴリズムの動作を制御するさまざまなパラメータを公開します。これらのパラメータは一般にハイパーパラメータと呼ばれ、その値はトレーニングされたモデルの品質に影響します。自動モデル チューニングは、最適なモデルを生成するアルゴリズムのハイパーパラメータのセットを見つけるプロセスです。
自動モデルチューニングでチューニングできるモデルは何ですか?,科学的に実行可能な限り、組み込みの SageMaker アルゴリズム、ディープニューラルネットワーク、または Docker イメージの形式で SageMaker に取り込んだ任意のアルゴリズムなど、任意のアルゴリズム上で Amazon SageMaker で自動モデルチューニングを実行できます。
Amazon SageMaker 以外でも自動モデルチューニングを使用できますか?,現時点ではそうではありません。最高のモデルチューニングパフォーマンスとエクスペリエンスは、Amazon SageMaker 内で実現されます。
自動モデルチューニングの基礎となるチューニング アルゴリズムは何ですか?,現在、ハイパーパラメータをチューニングするアルゴリズムは、ベイズ最適化のカスタマイズされた実装です。チューニング プロセス全体を通じて、顧客が指定した目標メトリックを最適化することを目的としています。具体的には、完了したトレーニング ジョブのオブジェクト メトリックをチェックし、その知識を使用して次のトレーニング ジョブのハイパーパラメータの組み合わせを推測します。
"自動モデルチューニングでは、チューニングに特定のハイパーパラメータを推奨しますか?",いいえ。特定のハイパーパラメータがモデルのパフォーマンスに与える影響はさまざまな要因によって異なり、あるハイパーパラメータが他のハイパーパラメータよりも重要であり、調整が必要であると断言することは困難です。Amazon SageMaker に組み込まれているアルゴリズムについては、ハイパーパラメータが調整可能かどうかを明示しています。
"ハイパーパラメータ調整ジョブにはどのくらいの時間がかかりますか?",ハイパーパラメータ調整ジョブの所要時間は、データのサイズ、基盤となるアルゴリズム、ハイパーパラメータの値など、複数の要因によって異なります。さらに、同時トレーニング ジョブの数とトレーニング ジョブの合計数も選択できます。これらの選択はすべて、ハイパーパラメータ調整ジョブの所要時間に影響します。
"モデルを高速かつ正確に最適化するなど、複数の目的を同時に最適化できますか?",現時点ではできません。現在、最適化するには単一の客観的なメトリックを指定するか、アルゴリズム コードを変更して、2 つ以上の有用なメトリック間の加重平均である新しいメトリックを生成し、その客観的なメトリックに向けてチューニング プロセスを最適化させる必要があります。
"自動モデルチューニングにはいくらかかりますか?",ハイパーパラメータ調整ジョブ自体には料金はかかりません。モデルトレーニングの料金に基づいて、ハイパーパラメータ調整ジョブによって起動されるトレーニングジョブごとに料金が発生します。
"Amazon SageMaker Autopilot と自動モデルチューニングのどちらを使用するかをどのように決めればよいですか?",Amazon SageMaker Autopilot は、特徴の前処理、アルゴリズムの選択、ハイパーパラメータの調整など、一般的な ML ワークフローのすべてを自動化しますが、特に分類と回帰のユースケースに重点を置いています。一方、自動モデルチューニングは、組み込みアルゴリズム、ディープラーニングフレームワーク、カスタムコンテナのいずれに基づいているかに関係なく、あらゆるモデルをチューニングするように設計されています。柔軟性と引き換えに、特定のアルゴリズム、調整するハイパーパラメータ、および対応する検索範囲を手動で選択する必要があります。
強化学習とは何ですか?,強化学習は、エージェントが自身の行動や経験からのフィードバックを使用して試行錯誤しながらインタラクティブな環境で学習できるようにする ML 技術です。
" Amazon SageMaker で強化学習モデルをトレーニングできますか?",はい、Amazon SageMaker では、教師あり学習モデルと教師なし学習モデルに加えて、強化学習モデルをトレーニングできます。
強化学習は教師あり学習とどう違うのでしょうか?,教師あり学習と強化学習はどちらも入力と出力のマッピングを使用しますが、エージェントに提供されるフィードバックがタスクを実行するための正しい一連のアクションである教師あり学習とは異なり、強化学習では、一連のアクションを通じて長期的な目標を達成するために報酬信号が最適化される遅延フィードバックを使用します。
"強化学習はいつ使用すればよいですか?",教師あり学習技術の目標はトレーニング データのパターンに基づいて正しい答えを見つけることですが、教師なし学習技術の目標はデータ ポイント間の類似点と相違点を見つけることです。対照的に、強化学習 (RL) 技術の目標は、結果を達成する方法が明確でない場合でも、望ましい結果を達成する方法を学習することです。その結果、RL は、ロボット工学、自律走行車、HVAC、産業用制御など、エージェントが自律的に決定を下すことができるインテリジェント アプリケーションの実現に適しています。
" RL モデルのトレーニングにはどのような環境を使用できますか?",Amazon SageMaker RL は、RL モデルのトレーニング用にさまざまな環境をサポートしています。AWS RoboMaker などの AWS サービス、オープンソース環境、Open AI Gym インターフェイスを使用して開発されたカスタム環境、MATLAB や SimuLink などの商用シミュレーション環境を使用できます。
"RL モデルをトレーニングするには、独自の RL エージェント アルゴリズムを作成する必要がありますか?",いいえ、Amazon SageMaker RL には、DQN、PPO、A3C などの RL エージェントアルゴリズムの実装を提供する Coach や Ray RLLib などの RL ツールキットが含まれています。
独自の RL ライブラリとアルゴリズム実装を持ち込んで Amazon SageMaker RL で実行できますか?,はい、独自の RL ライブラリとアルゴリズムの実装を Docker コンテナに持ち込み、Amazon SageMaker RL で実行できます。
" Amazon SageMaker RL を使用して分散ロールアウトを行うことはできますか?",はい。トレーニングを GPU インスタンスで実行し、シミュレーションを複数の CPU インスタンスで実行できる異種クラスターを選択することもできます。
Amazon SageMaker はどのようなデプロイメントオプションを提供していますか?,モデルを構築してトレーニングした後、Amazon SageMaker は予測を開始できるようにモデルをデプロイするための 3 つのオプションを提供します。リアルタイム推論は、レイテンシー要件がミリ秒、ペイロードサイズが最大 6 MB、処理時間が最大 60 秒のワークロードに適しています。バッチ変換は、事前に利用可能な大量のデータバッチに対するオフライン予測に最適です。非同期推論は、レイテンシー要件が 1 秒未満、ペイロードサイズが最大 1 GB、処理時間が最大 15 分ではないワークロード向けに設計されています。
Amazon SageMaker 非同期推論とは何ですか?,Amazon SageMaker 非同期推論は、受信リクエストをキューに入れて非同期的に処理します。このオプションは、ペイロードサイズが大きいリクエストや、到着時に処理する必要がある処理時間の長いリクエストに最適です。オプションで、コストを節約するために、リクエストをアクティブに処理していないときにインスタンス数をゼロにスケールダウンするように自動スケーリング設定を構成することもできます。
リクエストをアクティブに処理していないときにインスタンス数をゼロにスケールダウンするように自動スケーリング設定を構成するにはどうすればよいですか?,リクエストをアクティブに処理していないときにコストを節約するために、Amazon SageMaker 非同期推論エンドポイントのインスタンス数をゼロにスケールダウンできます。「approximateBacklogPerInstance」カスタムメトリックに基づいてスケールするスケーリングポリシーを定義し、「MinCapacity」値をゼロに設定する必要があります。詳細な手順については、開発者ガイドの非同期エンドポイントの自動スケールのセクションをご覧ください。
Amazon SageMaker Serverless Inference とは何ですか?,Amazon SageMaker Serverless Inference は、ML モデルのデプロイとスケーリングを容易にする専用のサーバーレスモデル提供オプションです。SageMaker Serverless Inference エンドポイントは、コンピューティングリソースを自動的に開始し、トラフィックに応じてスケールインおよびスケールアウトするため、インスタンスタイプを選択したり、プロビジョニングされた容量を実行したり、スケーリングを管理したりする必要がなくなります。オプションで、サーバーレス推論エンドポイントのメモリ要件を指定できます。アイドル期間ではなく、推論コードの実行期間と処理されたデータ量に対してのみ料金が発生します。
Amazon SageMaker Serverless Inference を使用する必要があるのはなぜですか?,Amazon SageMaker Serverless Inference は、事前にキャパシティーをプロビジョニングしたり、スケーリングポリシーを管理したりする必要がなくなるため、開発者のエクスペリエンスが簡素化されます。SageMaker Serverless Inference は、使用パターンに基づいて、数秒以内に数十から数千の推論に瞬時にスケールできるため、断続的または予測不可能なトラフィックを伴う ML アプリケーションに最適です。たとえば、給与処理会社が使用するチャットボットサービスでは、月末に問い合わせが増加しますが、月の残りの期間はトラフィックが断続的です。このようなシナリオで 1 か月分のインスタンスをプロビジョニングすると、アイドル期間の料金を支払うことになり、費用対効果が低くなります。SageMaker Serverless Inference は、事前にトラフィックを予測したり、スケーリングポリシーを管理したりすることなく、すぐに使用できる自動で高速なスケーリングを提供することで、このようなタイプのユースケースに対応します。さらに、推論コードを実行するコンピューティング時間 (ミリ秒単位で請求) とデータ処理に対してのみ料金が発生するため、断続的なトラフィックを伴うワークロードにとって費用対効果の高いオプションとなります。
Amazon SageMaker シャドウテストとは何ですか?,SageMaker は、現在デプロイされているモデルに対してパフォーマンスをテストすることで、本番リリース前に新しい ML モデルを評価するシャドウ テストの実行を支援します。SageMaker は、新しいモデルを現在の本番モデルと並行してシャドウ モードでデプロイし、本番トラフィックのユーザー指定部分を新しいモデルにミラーリングします。オプションで、オフライン比較のためにモデル推論をログに記録します。また、本番モデルとシャドウ モデル間のレイテンシーやエラー率などの主要なパフォーマンス メトリックの比較を示すライブ ダッシュボードも提供し、新しいモデルを本番環境に昇格させるかどうかの判断に役立ちます。
シャドウテストに SageMaker を使用する必要があるのはなぜですか?,SageMaker は、シャドウバリアントの設定と監視のプロセスを簡素化し、ライブの本番トラフィックで新しい ML モデルのパフォーマンスを評価できるようにします。SageMaker を使用すると、シャドウテスト用にインフラストラクチャを調整する必要がなくなります。シャドウバリアントにミラーリングされるトラフィックの割合やテストの期間などのテストパラメータを制御できます。その結果、小規模から始めて、モデルのパフォーマンスに自信が持てるようになったら、新しいモデルへの推論リクエストを増やすことができます。SageMaker は、主要なメトリクス間のパフォーマンスの違いを表示するライブダッシュボードを作成するため、モデルのパフォーマンスを簡単に比較して、新しいモデルが本番モデルとどのように異なるかを評価できます。
Amazon SageMaker Inference Recommender とは何ですか?,Amazon SageMaker Inference Recommender は、Amazon SageMaker の新しい機能で、SageMaker ML インスタンス全体でパフォーマンスベンチマークとモデルパフォーマンスのチューニングを自動化することで、ML モデルを本番環境に導入するために必要な時間を短縮します。SageMaker Inference Recommender を使用して、最高のパフォーマンスを提供しコストを最小限に抑えるエンドポイントにモデルをデプロイできるようになりました。インスタンスタイプを選択しながら数分で SageMaker Inference Recommender を開始し、数時間以内に最適なエンドポイント構成の推奨事項を取得できるため、数週間に及ぶ手動テストとチューニングの時間が不要になります。SageMaker Inference Recommender では、負荷テスト中に使用した SageMaker ML インスタンスに対してのみ料金が発生し、追加料金は発生しません。
Amazon SageMaker Inference Recommender を使用する必要があるのはなぜですか?,パフォーマンスを向上させてコストを削減するために適切なエンドポイント構成の推奨事項が必要な場合は、SageMaker Inference Recommender を使用する必要があります。以前は、モデルをデプロイしたいデータ サイエンティストは、適切なエンドポイント構成を選択するために手動ベンチマークを実行する必要がありました。まず、モデルとサンプル ペイロードのリソース要件に基づいて、70 を超える利用可能なインスタンス タイプから適切な ML インスタンス タイプを選択し、次にさまざまなハードウェアを考慮してモデルを最適化する必要がありました。次に、レイテンシーとスループットの要件が満たされ、コストが低いことを検証するために、広範な負荷テストを実施する必要がありました。SageMaker Inference Recommender を使用すると、次の操作を簡単に実行できるため、この複雑さが解消されます。1) インスタンスの推奨事項を使用して数分で開始する。2) インスタンス タイプ全体で負荷テストを実施して、数時間以内にエンドポイント構成に関する推奨事項を取得する。3) コンテナとモデル サーバーのパラメータを自動的に調整し、特定のインスタンス タイプに対してモデルの最適化を実行する。
Amazon SageMaker Inference Recommender は他の AWS サービスとどのように連携しますか?,データサイエンティストは、SageMaker Studio、AWS SDK for Python (Boto3)、または AWS CLI から Amazon SageMaker Inference Recommender にアクセスできます。登録されたモデルバージョンの SageMaker モデルレジストリで、SageMaker Studio 内でデプロイメントの推奨事項を取得できます。データサイエンティストは、SageMaker Studio、AWS SDK、または AWS CLI を通じて推奨事項を検索およびフィルタリングできます。
" Amazon SageMaker Inference Recommender は、マルチモデルエンドポイントまたはマルチコンテナエンドポイントをサポートできますか?",いいえ、現在はエンドポイントごとに 1 つのモデルのみをサポートしています。
SageMaker Inference Recommender はどのようなタイプのエンドポイントをサポートしていますか?,現在、リアルタイム エンドポイントのみをサポートしています。
あるリージョンで SageMaker Inference Recommender を使用し、別のリージョンでベンチマークを行うことはできますか?,開始時には、AWS 中国リージョンを除く、Amazon SageMaker がサポートするすべてのリージョンがサポートされます。
Amazon SageMaker Inference Recommender は Amazon EC2 Inf1 インスタンスをサポートしていますか?,はい、すべてのタイプのコンテナをサポートしています。AWS Inferentia チップをベースにした Amazon EC2 Inf1 では、Neuron コンパイラーまたは Amazon SageMaker Neo を使用してコンパイルされたモデルアーティファクトが必要です。Inferentia ターゲットのコンパイル済みモデルと関連するコンテナイメージ URI を取得したら、Amazon SageMaker Inference Recommender を使用して、さまざまな Inferentia インスタンスタイプをベンチマークできます。
Amazon SageMaker モデルモニターとは何ですか?,Amazon SageMaker Model Monitor を使用すると、開発者はコンセプトドリフトを検出して修正できます。SageMaker Model Monitor は、デプロイされたモデル内のコンセプトドリフトを自動的に検出し、問題の原因を特定するのに役立つ詳細なアラートを提供します。SageMaker でトレーニングされたすべてのモデルは、Amazon SageMaker Studio で収集および表示できる主要なメトリクスを自動的に出力します。SageMaker Studio 内から、収集するデータ、その表示方法、アラートを受信するタイミングを設定できます。
Amazon SageMaker が実行されるインフラストラクチャにアクセスできますか?,いいえ。Amazon SageMaker はお客様に代わってコンピューティングインフラストラクチャを運用し、ヘルスチェック、セキュリティパッチの適用、その他の定期的なメンテナンスを実行できるようにします。また、カスタム推論コードを使用してトレーニングから得たモデル成果物を、独自のホスティング環境にデプロイすることもできます。
"本番稼働後に Amazon SageMaker モデルのサイズとパフォーマンスを拡張するにはどうすればよいですか?",Amazon SageMaker ホスティングは、Application Auto Scaling を使用して、アプリケーションに必要なパフォーマンスに合わせて自動的にスケールします。さらに、エンドポイント設定を変更することで、ダウンタイムを発生させずにインスタンスの数とタイプを手動で変更することもできます。
Amazon SageMaker の本番環境を監視するにはどうすればよいですか?,Amazon SageMaker はパフォーマンスメトリクスを Amazon CloudWatch Metrics に送信するため、メトリクスを追跡し、アラームを設定し、本番トラフィックの変化に自動的に対応できます。さらに、Amazon SageMaker は Amazon CloudWatch Logs にログを書き込むため、本番環境の監視とトラブルシューティングが可能になります。
Amazon SageMaker ではどのような種類のモデルをホストできますか?,Amazon SageMaker は、推論 Docker イメージの文書化された仕様に準拠する任意のモデルをホストできます。これには、Amazon SageMaker モデル成果物と推論コードから作成されたモデルが含まれます。
Amazon SageMaker は、同時リアルタイム API リクエストをいくつサポートしていますか?,Amazon SageMaker は、1 秒あたり多数のトランザクションに対応できるように設計されています。正確な数は、デプロイされたモデルと、モデルがデプロイされるインスタンスの数とタイプによって異なります。
バッチ変換とは何ですか?,バッチ変換を使用すると、大規模または小規模のバッチ データに対して予測を実行できます。データセットを複数のチャンクに分割したり、リアルタイム エンドポイントを管理したりする必要はありません。シンプルな API を使用すると、多数のデータ レコードの予測を要求し、データを迅速かつ簡単に変換できます。
Amazon SageMaker Edge Manager とは何ですか?,Amazon SageMaker Edge Manager を使用すると、スマートカメラ、ロボット、パソコン、モバイルデバイスなどのエッジデバイス群で ML モデルを簡単に最適化、保護、監視、保守できます。SageMaker Edge Manager は、ML 開発者がさまざまなエッジデバイスで ML モデルを大規模に運用するのに役立ちます。
Amazon SageMaker Edge Manager を使い始めるにはどうすればよいですか?,Amazon SageMaker Edge Manager の使用を開始するには、クラウドでトレーニング済みの ML モデルをコンパイルしてパッケージ化し、デバイスを登録し、SageMaker Edge Manager SDK を使用してデバイスを準備する必要があります。モデルをデプロイ用に準備するために、SageMaker Edge Manager は SageMaker Neo を使用して、ターゲットエッジハードウェア用にモデルをコンパイルします。モデルがコンパイルされると、SageMaker Edge Manager は AWS が生成したキーを使用してモデルに署名し、モデルをランタイムと必要な認証情報とともにパッケージ化して、デプロイの準備を整えます。デバイス側では、デバイスを SageMaker Edge Manager に登録し、SageMaker Edge Manager SDK をダウンロードして、指示に従ってデバイスに SageMaker Edge Manager エージェントをインストールします。チュートリアルノートブックには、モデルを準備し、SageMaker Edge Manager を使用してエッジデバイスにモデルを接続する方法のステップバイステップの例が示されています。
Amazon SageMaker Edge Manager ではどのようなデバイスがサポートされていますか?,Amazon SageMaker Edge Manager は、Linux および Windows オペレーティングシステムで一般的な CPU (ARM、x86) および GPU (ARM、Nvidia) ベースのデバイスをサポートしています。今後、SageMaker Edge Manager は、SageMaker Neo でもサポートされているより多くの組み込みプロセッサとモバイル プラットフォームをサポートするように拡張される予定です。
Amazon SageMaker Edge Manager を使用するには、Amazon SageMaker を使用してモデルをトレーニングする必要がありますか?,いいえ、必要ありません。モデルを他の場所でトレーニングすることも、オープンソースまたはモデルベンダーから事前にトレーニングされたモデルを使用することもできます。
Amazon SageMaker Edge Manager を使用するには、Amazon SageMaker Neo を使用してモデルをコンパイルする必要がありますか?,はい、必要です。Amazon SageMaker Neo はモデルを実行可能ファイルに変換してコンパイルし、それをパッケージ化してエッジデバイスにデプロイできます。モデルパッケージがデプロイされると、Amazon SageMaker Edge Manager エージェントがモデルパッケージを解凍し、デバイス上でモデルを実行します。
モデルをエッジ デバイスにデプロイするにはどうすればよいですか?,Amazon SageMaker Edge Manager は、指定された Amazon S3 バケットにモデル パッケージを保存します。AWS IoT Greengrass が提供する無線 (OTA) デプロイメント機能、または任意の他のデプロイメント メカニズムを使用して、S3 バケットからデバイスにモデル パッケージをデプロイできます。
Amazon SageMaker Edge Manager SDK は SageMaker Neo ランタイム (dlr) とどう違うのですか?,Neo dlr は、Amazon SageMaker Neo サービスによってコンパイルされたモデルのみを実行するオープンソースのランタイムです。オープンソースの dlr と比較すると、SageMaker Edge Manager SDK には、追加のセキュリティ、モデル管理、およびモデル提供機能を備えたエンタープライズ グレードのオンデバイス エージェントが含まれています。SageMaker Edge Manager SDK は、大規模な本番環境への展開に適しています。
Amazon SageMaker Edge Manager は AWS IoT Greengrass とどのように関連していますか?,Amazon SageMaker Edge Manager と AWS IoT Greengrass は、IoT ソリューションで連携できます。ML モデルが SageMaker Edge Manager でパッケージ化されたら、AWS IoT Greengrass の OTA 更新機能を使用して、モデル パッケージをデバイスにデプロイできます。AWS IoT Greengrass を使用すると、IoT デバイスをリモートで監視できます。一方、SageMaker Edge Manager は、デバイス上の ML モデルの監視と保守に役立ちます。
Amazon SageMaker Edge Manager は AWS Panorama とどのような関係がありますか? Amazon SageMaker Edge Manager と AWS Panorama はいつ使用すればよいですか?,AWS は、エッジデバイスでモデルを実行するための最も幅広く奥深い機能を提供します。コンピュータビジョン、音声認識、予知保全など、幅広いユースケースをサポートするサービスがあります。カメラやアプライアンスなどのエッジデバイスでコンピュータビジョンを実行したい企業には、AWS Panorama がお勧めです。Panorama は、エッジデバイス用のすぐにデプロイ可能なコンピュータビジョンアプリケーションを提供します。クラウドコンソールにログインし、Amazon S3 または SageMaker で使用するモデルを指定してから、ビジネスロジックを Python スクリプトとして記述するだけで、AWS Panorama を簡単に使い始めることができます。AWS Panorama は、ターゲットデバイス用にモデルをコンパイルしてアプリケーションパッケージを作成するので、数回クリックするだけでデバイスにデプロイできます。さらに、独自のカスタムアプリケーションを構築したい独立系ソフトウェアベンダーは AWS Panorama SDK を使用でき、デバイスメーカーは Device SDK を使用して AWS Panorama 用にデバイスを認定できます。独自のモデルを構築し、モデル機能をより細かく制御したいお客様は、Amazon SageMaker Edge Manager を使用できます。 SageMaker Edge Manager は、自然言語処理、不正検出、予測メンテナンスなどのあらゆるユースケース向けに、スマートカメラ、スマートスピーカー、ロボットなどのエッジデバイスのフリート全体で ML モデルを準備、実行、監視、更新するためのマネージドサービスです。SageMaker Edge Manager は、さまざまなモデル機能の設計やモデルのドリフトの監視など、モデルを制御したい ML エッジ開発者向けです。すべての ML エッジ開発者は、SageMaker コンソールと SageMaker API を通じて SageMaker Edge Manager を使用できます。SageMaker Edge Manager は、クラウドでモデルを構築、トレーニング、デプロイするための SageMaker の機能をエッジデバイスにもたらします。
Amazon SageMaker Edge Manager はどの AWS リージョンで利用できますか?,Amazon SageMaker Edge Manager は、米国東部 (バージニア北部)、米国東部 (オハイオ)、米国西部 (オレゴン)、欧州 (アイルランド)、欧州 (フランクフルト)、アジアパシフィック (東京) の 6 つの AWS リージョンで利用できます。詳細については、AWS リージョンのサービス一覧をご覧ください。
Amazon SageMaker Neo とは何ですか?,Amazon SageMaker Neo を使用すると、ML モデルを一度トレーニングすれば、クラウドやエッジのどこでも実行できます。SageMaker Neo は、複数のハードウェア プラットフォームにデプロイできる一般的なディープラーニング フレームワークで構築されたモデルを自動的に最適化します。最適化されたモデルは、一般的な ML モデルの最大 25 倍の速度で実行され、消費するリソースは 10 分の 1 未満です。
Amazon SageMaker Neo を使い始めるにはどうすればよいですか?,Amazon SageMaker Neo を使い始めるには、Amazon SageMaker コンソールにログインし、トレーニング済みのモデルを選択し、例に従ってモデルをコンパイルし、結果のモデルをターゲットのハードウェア プラットフォームにデプロイします。
Amazon SageMaker Neo の主なコンポーネントは何ですか?,Amazon SageMaker Neo には、コンパイラとランタイムという 2 つの主要コンポーネントが含まれています。まず、Neo コンパイラはさまざまなフレームワークによってエクスポートされたモデルを読み取ります。次に、フレームワーク固有の関数と操作をフレームワークに依存しない中間表現に変換します。次に、一連の最適化を実行します。その後、コンパイラは最適化された操作のバイナリ コードを生成し、共有オブジェクト ライブラリに書き込みます。コンパイラは、モデル定義とパラメータも別々のファイルに保存します。実行中、Neo ランタイムは、コンパイラによって生成された成果物 (モデル定義、パラメータ、およびモデルを実行するための共有オブジェクト ライブラリ) をロードします。
Amazon SageMaker Neo を使用してモデルを変換するには、Amazon SageMaker を使用してモデルをトレーニングする必要がありますか?,いいえ。他の場所でモデルをトレーニングし、Neo を使用して Amazon SageMaker ML インスタンスまたは AWS IoT Greengrass 対応デバイス用に最適化することができます。
Amazon SageMaker Neo はどのモデルをサポートしていますか?,現在、Amazon SageMaker Neo は、コンピュータビジョンアプリケーションを強化する最も人気のあるディープラーニングモデルと、現在 Amazon SageMaker で使用されている最も人気のある決定木モデルをサポートしています。Neo は、MXNet と TensorFlow でトレーニングされた AlexNet、ResNet、VGG、Inception、MobileNet、SqueezeNet、および DenseNet モデル、および XGBoost でトレーニングされた分類およびランダムカットフォレストモデルのパフォーマンスを最適化します。
Amazon SageMaker Neo はどのハードウェアプラットフォームをサポートしていますか?,サポートされているクラウドインスタンス、エッジデバイス、フレームワークのバージョンのリストは、Amazon SageMaker Neo のドキュメントで確認できます。
Amazon SageMaker Neo はどの AWS リージョンで利用できますか?,サポートされているリージョンの一覧を確認するには、AWS リージョンサービス一覧を参照してください。
Amazon SageMaker Savings Plans とは何ですか?,Amazon SageMaker Savings Plans は、1 年または 3 年の期間にわたって一定の使用量 ($/時間で測定) を約束する代わりに、Amazon SageMaker の柔軟な使用量ベースの料金モデルを提供します。Amazon SageMaker Savings Plans は最も柔軟性が高く、コストを最大 64% 削減するのに役立ちます。これらのプランは、インスタンスファミリー、サイズ、またはリージョンに関係なく、SageMaker Studio ノートブック、SageMaker On-Demand ノートブック、SageMaker Processing、SageMaker Data Wrangler、SageMaker Training、SageMaker Real-Time Inference、および SageMaker Batch Transform を含む、対象となる SageMaker ML インスタンスの使用に自動的に適用されます。たとえば、推論ワークロードの CPU インスタンス ml.c5.xlarge を米国東部 (オハイオ) で実行しているインスタンスから、米国西部 (オレゴン) のインスタンス ml.Inf1 にいつでも変更でき、自動的に Savings Plans の料金を支払い続けることができます。
Amazon SageMaker Savings Plans を使用する必要があるのはなぜですか?,Amazon SageMaker インスタンスの使用量 ($/時間で測定) が一定で、複数の SageMaker コンポーネントを使用している場合、またはテクノロジー構成 (インスタンス ファミリーやリージョンなど) が時間の経過とともに変更されることが予想される場合は、SageMaker Savings Plans を使用すると、アプリケーションのニーズや新しいイノベーションに基づいて基盤となるテクノロジー構成を柔軟に変更しながら、節約を最大化することが簡単になります。Savings Plans 料金は、対象となるすべての ML インスタンスの使用に自動的に適用され、手動で変更する必要はありません。
Amazon SageMaker Savings Plans を使い始めるにはどうすればよいですか?,Savings Plans は、AWS マネジメントコンソールの AWS Cost Explorer から、または API/CLI を使用して開始できます。AWS Cost Explorer で提供される推奨事項を使用して Savings Plans に簡単にコミットし、最大の節約を実現できます。推奨される時間単位のコミットメントは、オンデマンドの過去の使用量と、選択したプランタイプ、期間、および支払いオプションに基づいています。Savings Plan にサインアップすると、コンピューティング使用量は割引された Savings Plans 価格で自動的に請求され、コミットメントを超えた使用量は通常のオンデマンド料金で請求されます。
Amazon SageMaker の Savings Plans と Amazon EC2 の Compute Savings Plans の違いは何ですか?,Amazon SageMaker の Savings Plans と EC2 の Savings Plans の違いは、含まれるサービスにあります。SageMaker Savings Plans は、SageMaker ML インスタンスの使用にのみ適用されます。
Savings Plans は AWS Organizations/Consolidated Billing とどのように連携しますか?,Savings Plans は、AWS Organization/Consolidated Billing ファミリー内のどのアカウントでも購入できます。デフォルトでは、Savings Plans によって提供される特典は、AWS Organization/Consolidated Billing ファミリー内のすべてのアカウントの使用に適用されます。ただし、Savings Plans の特典を、それを購入したアカウントのみに制限することもできます。
